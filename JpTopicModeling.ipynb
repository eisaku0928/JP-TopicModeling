{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773c821c-0eb2-40ea-a28b-bc2fe2660b3d",
   "metadata": {},
   "source": [
    "# Topic Modeling (LDA) on Japanese Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00850b-3959-4186-ac64-ec5ac4997aa0",
   "metadata": {},
   "source": [
    "## 0. Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68c20143-e93b-4fac-b340-c795afd8e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mojimoji\n",
    "!pip install MeCab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9055ca35-e325-4f4f-a344-7ce918bb5f20",
   "metadata": {},
   "source": [
    "## 1. Reading in Japanese news corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2010904-08c5-4ce6-88f5-b10f9d74ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import MeCab\n",
    "import mojimoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdef73b1-182f-4eb5-8dd9-613a9e99a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news corpus gained from: https://nxdataka.netlify.app/ldncsv/\n",
    "df = pd.read_csv(\"./livedoornews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7088d1f2-cc9d-487c-826d-017e46d2c818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7367, 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7102858f-13f2-4af5-9add-76e41885b895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://news.livedoor.com/article/detail/5978741/</td>\n",
       "      <td>2011-10-30T10:15:00+0900</td>\n",
       "      <td>【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か</td>\n",
       "      <td>2005年11月から翌2006年7月まで読売新聞にて連載された、直木賞作家・角田光代による初...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6322901/</td>\n",
       "      <td>2012-02-29T11:45:00+0900</td>\n",
       "      <td>藤原竜也、中学生とともにロケット打ち上げに成功</td>\n",
       "      <td>「アンテナを張りながら生活をしていけばいい」\\n2月28日、映画『おかえり、はやぶさ』（3月...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6176324/</td>\n",
       "      <td>2012-01-09T14:00:00+0900</td>\n",
       "      <td>『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席</td>\n",
       "      <td>3月2日より全国ロードショーとなる、スティーブン・スピルバーグの待望の監督最新作『戦火の馬』...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6573929/</td>\n",
       "      <td>2012-05-19T12:00:00+0900</td>\n",
       "      <td>香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」</td>\n",
       "      <td>女優の香里奈が18日、都内で行われた映画『ガール』（5月26日公開）の女子高生限定試写会にサ...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://news.livedoor.com/article/detail/5914880/</td>\n",
       "      <td>2011-10-05T19:11:00+0900</td>\n",
       "      <td>ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」</td>\n",
       "      <td>5日、東京・千代田区の内幸町ホールにて、映画『キャプテン・アメリカ/ザ・ファースト・アベンジ...</td>\n",
       "      <td>movie-enter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6530260/</td>\n",
       "      <td>2012-05-05T09:55:00+0900</td>\n",
       "      <td>好きな戦士を作ってドラゴンボールの世界で天下一武道会優勝だ！「挑戦！天下一武道会」【Andr...</td>\n",
       "      <td>どんな戦士を作るかはユーザー次第！\\n国民的人気を誇る鳥山明氏のマンガ／アニメである「DRA...</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7363</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6681611/</td>\n",
       "      <td>2012-06-21T20:55:00+0900</td>\n",
       "      <td>NTTドコモ、GALAXY SIII SC-06DとF-09D ANTEPRIMAの発売日を...</td>\n",
       "      <td>GALAXY SIIIが6月28日、F-09D ANTEPRIMAが6月27日に発売！\\nN...</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7364</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6856578/</td>\n",
       "      <td>2012-08-15T11:55:00+0900</td>\n",
       "      <td>NTTドコモ、Android向け「docomo Wi-Fiかんたん接続アプリ」をバージョンア...</td>\n",
       "      <td>shimajiro@mobiler\\nNTTドコモは、同社の公衆無線LANサービス「doco...</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7365</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6678539/</td>\n",
       "      <td>2012-06-21T06:55:00+0900</td>\n",
       "      <td>NTTドコモ、PRADA Phone by LG L-02Dのデコメ絵文字popが正常に表示...</td>\n",
       "      <td>PRADA Phone by LG L-02Dにソフトウェア更新！\\nNTTドコモは20日、...</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7366</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6869011/</td>\n",
       "      <td>2012-08-20T08:55:00+0900</td>\n",
       "      <td>NTTドコモ、公式オンラインショップでも端末複数台購入で最大10,500円／台の割り引きが受...</td>\n",
       "      <td>NTTドコモは17日、公式オンラインショップ「ドコモオンラインショップ」において端末を複数台...</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7367 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0     http://news.livedoor.com/article/detail/5978741/   \n",
       "1     http://news.livedoor.com/article/detail/6322901/   \n",
       "2     http://news.livedoor.com/article/detail/6176324/   \n",
       "3     http://news.livedoor.com/article/detail/6573929/   \n",
       "4     http://news.livedoor.com/article/detail/5914880/   \n",
       "...                                                ...   \n",
       "7362  http://news.livedoor.com/article/detail/6530260/   \n",
       "7363  http://news.livedoor.com/article/detail/6681611/   \n",
       "7364  http://news.livedoor.com/article/detail/6856578/   \n",
       "7365  http://news.livedoor.com/article/detail/6678539/   \n",
       "7366  http://news.livedoor.com/article/detail/6869011/   \n",
       "\n",
       "                      datetime  \\\n",
       "0     2011-10-30T10:15:00+0900   \n",
       "1     2012-02-29T11:45:00+0900   \n",
       "2     2012-01-09T14:00:00+0900   \n",
       "3     2012-05-19T12:00:00+0900   \n",
       "4     2011-10-05T19:11:00+0900   \n",
       "...                        ...   \n",
       "7362  2012-05-05T09:55:00+0900   \n",
       "7363  2012-06-21T20:55:00+0900   \n",
       "7364  2012-08-15T11:55:00+0900   \n",
       "7365  2012-06-21T06:55:00+0900   \n",
       "7366  2012-08-20T08:55:00+0900   \n",
       "\n",
       "                                                  title  \\\n",
       "0                   【DVDエンター！】誘拐犯に育てられた女が目にした真実は、孤独か幸福か   \n",
       "1                               藤原竜也、中学生とともにロケット打ち上げに成功   \n",
       "2                     『戦火の馬』ロイヤル・プレミアにウィリアム王子＆キャサリン妃が出席   \n",
       "3                      香里奈、女子高生100人のガチンコ質問に回答「ラーメンも食べる」   \n",
       "4                      ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」   \n",
       "...                                                 ...   \n",
       "7362  好きな戦士を作ってドラゴンボールの世界で天下一武道会優勝だ！「挑戦！天下一武道会」【Andr...   \n",
       "7363  NTTドコモ、GALAXY SIII SC-06DとF-09D ANTEPRIMAの発売日を...   \n",
       "7364  NTTドコモ、Android向け「docomo Wi-Fiかんたん接続アプリ」をバージョンア...   \n",
       "7365  NTTドコモ、PRADA Phone by LG L-02Dのデコメ絵文字popが正常に表示...   \n",
       "7366  NTTドコモ、公式オンラインショップでも端末複数台購入で最大10,500円／台の割り引きが受...   \n",
       "\n",
       "                                                   body        media  \n",
       "0     2005年11月から翌2006年7月まで読売新聞にて連載された、直木賞作家・角田光代による初...  movie-enter  \n",
       "1     「アンテナを張りながら生活をしていけばいい」\\n2月28日、映画『おかえり、はやぶさ』（3月...  movie-enter  \n",
       "2     3月2日より全国ロードショーとなる、スティーブン・スピルバーグの待望の監督最新作『戦火の馬』...  movie-enter  \n",
       "3     女優の香里奈が18日、都内で行われた映画『ガール』（5月26日公開）の女子高生限定試写会にサ...  movie-enter  \n",
       "4     5日、東京・千代田区の内幸町ホールにて、映画『キャプテン・アメリカ/ザ・ファースト・アベンジ...  movie-enter  \n",
       "...                                                 ...          ...  \n",
       "7362  どんな戦士を作るかはユーザー次第！\\n国民的人気を誇る鳥山明氏のマンガ／アニメである「DRA...         smax  \n",
       "7363  GALAXY SIIIが6月28日、F-09D ANTEPRIMAが6月27日に発売！\\nN...         smax  \n",
       "7364  shimajiro@mobiler\\nNTTドコモは、同社の公衆無線LANサービス「doco...         smax  \n",
       "7365  PRADA Phone by LG L-02Dにソフトウェア更新！\\nNTTドコモは20日、...         smax  \n",
       "7366  NTTドコモは17日、公式オンラインショップ「ドコモオンラインショップ」において端末を複数台...         smax  \n",
       "\n",
       "[7367 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c6bd5-f0a2-4865-9708-6efc13c91b24",
   "metadata": {},
   "source": [
    "## 2. Preprocess text (Tokenization + POS tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42a60e69-ec1f-4fc7-a69d-c04e1ecffd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MeCabを使った処理のためのクラス\n",
    "class MeCabHandler:\n",
    "    def __init__(self, tagger):\n",
    "        self._handler = tagger\n",
    "\n",
    "    def surface(self, text):\n",
    "        self._handler.parse(\"\")\n",
    "        result = self._handler.parseToNode(text)\n",
    "        filtered_words = []\n",
    "        while result:\n",
    "            filtered_words.append(result.surface)\n",
    "            result = result.next\n",
    "\n",
    "        return filtered_words\n",
    "\n",
    "    def pos(self, text):\n",
    "        self._handler.parse(\"\")\n",
    "        result = self._handler.parseToNode(text)\n",
    "        pos = []\n",
    "        while result:\n",
    "            features = result.feature.split(',')\n",
    "            pos.append(features[0])\n",
    "            result = result.next\n",
    "\n",
    "        return pos\n",
    "\n",
    "\n",
    "#前処理用の関数\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = mojimoji.zen_to_han(text, kana=False)\n",
    "    text = mojimoji.han_to_zen(text, digit=False, ascii=False)\n",
    "    text = text.translate(str.maketrans({\n",
    "        '!': '！', '\"': '”', '#': '＃', '$': '＄', '%': '％', '&': '＆', '\\'': '’',\n",
    "        '(': '（', ')': '）', '*': '＊', '+': '＋', ',': '，', '-': '−', '.': '．',\n",
    "        '/': '／', ':': '：', ';': '；', '<': '＜', '=': '＝', '>': '＞', '?': '？',\n",
    "        '@': '＠', '[': '［', '\\\\': '＼', ']': '］', '^': '＾', '_': '＿', '`': '｀',\n",
    "        '{': '｛', '|': '｜', '}': '｝'\n",
    "        }))\n",
    "    zenkaku_leftsingle = b'\\xe2\\x80\\x98'.decode('utf-8')\n",
    "    text = re.sub('[’´｀]', zenkaku_leftsingle, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "#文字コードを確認する関数\n",
    "def getEncode(filepath):\n",
    "    encs = \"iso-2022-jp euc-jp shift_jis utf-8\".split()\n",
    "    for enc in encs:\n",
    "        with open(filepath, encoding=enc) as fr:\n",
    "            try:\n",
    "                fr = fr.read()\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        return enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19f3386c-8ee5-45a4-baf0-8e250f051b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessDf(filename):\n",
    "    \"\"\"Reads in Japanese news dataframe from filename, and returns a corpus of the body text tokenized,\n",
    "    as well as part-of-speech (pos) tags for them.\"\"\"\n",
    "    # read in and define dependencies\n",
    "    mt = MeCab.Tagger(\"-Ochasen -u \" + \"user_dict.dic\")\n",
    "    handler = MeCabHandler(mt)\n",
    "    enc = getEncode(FILENAME)\n",
    "    df = pd.read_csv(FILENAME, encoding=enc)\n",
    "    preprocessedRow = OrderedDict()\n",
    "    outDf = pd.DataFrame()\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        url = row[\"url\"]\n",
    "        datetime = row[\"datetime\"]\n",
    "        title = row[\"title\"]\n",
    "        body = row[\"body\"]\n",
    "        media = row[\"media\"]\n",
    "        \n",
    "        # preprocess text\n",
    "        filteredText = preprocess(body)\n",
    "        tokenizedText = \" \".join(handler.surface(filteredText)[1:-1])\n",
    "        \n",
    "        preprocessedRow[\"url\"] = url\n",
    "        preprocessedRow[\"datetime\"] = datetime\n",
    "        preprocessedRow[\"body\"] = tokenizedText\n",
    "        \n",
    "        # calculate pos rate\n",
    "        computePosRate(handler, tokenizedText, preprocessedRow)\n",
    "        \n",
    "        # Append to Dataframe\n",
    "        outDf = outDf.append(pd.DataFrame(preprocessedRow, index=[i]))\n",
    "        \n",
    "    return outDf\n",
    "\n",
    "def computePosRate(handler, text, preprocessedRow):\n",
    "    # Calculate pos_rate\n",
    "    pos = handler.pos(text)[1:-1]\n",
    "\n",
    "    cnt = Counter(pos).most_common()\n",
    "    wc = len(pos)\n",
    "    preprocessedRow[\"WC\"] = wc\n",
    "    for tpl in cnt:\n",
    "        preprocessedRow[tpl[0]] = '{:.2f}'.format((tpl[1] / wc)*100)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ee69e1d-b65c-45c4-9971-eddb70145ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filename for input corpus\n",
    "FILENAME = './livedoornews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf624c0c-3fd7-4807-80ca-9d71b35b281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessedDf = preprocessDf(FILENAME)\n",
    "preprocessedDf.to_csv(\"./preprocessed_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fffecfbb-ccff-4663-afc2-e360a8ece0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>datetime</th>\n",
       "      <th>body</th>\n",
       "      <th>WC</th>\n",
       "      <th>名詞</th>\n",
       "      <th>助詞</th>\n",
       "      <th>記号</th>\n",
       "      <th>動詞</th>\n",
       "      <th>助動詞</th>\n",
       "      <th>副詞</th>\n",
       "      <th>連体詞</th>\n",
       "      <th>接頭詞</th>\n",
       "      <th>接続詞</th>\n",
       "      <th>形容詞</th>\n",
       "      <th>感動詞</th>\n",
       "      <th>フィラー</th>\n",
       "      <th>その他</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://news.livedoor.com/article/detail/5978741/</td>\n",
       "      <td>2011-10-30T10:15:00+0900</td>\n",
       "      <td>2005 年 11 月 から 翌 2006 年 7 月 まで 読売新聞 にて 連載 さ れ ...</td>\n",
       "      <td>800</td>\n",
       "      <td>42.12</td>\n",
       "      <td>23.62</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.88</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6322901/</td>\n",
       "      <td>2012-02-29T11:45:00+0900</td>\n",
       "      <td>「 アンテナ を 張り ながら 生活 を し て いけ ば いい 」 2 月 28 日 、 ...</td>\n",
       "      <td>1264</td>\n",
       "      <td>34.18</td>\n",
       "      <td>26.66</td>\n",
       "      <td>12.66</td>\n",
       "      <td>13.13</td>\n",
       "      <td>8.86</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6176324/</td>\n",
       "      <td>2012-01-09T14:00:00+0900</td>\n",
       "      <td>3 月 2 日 より 全国 ロードショー と なる 、 スティーブン ・ スピルバーグ の ...</td>\n",
       "      <td>1267</td>\n",
       "      <td>38.20</td>\n",
       "      <td>26.52</td>\n",
       "      <td>12.47</td>\n",
       "      <td>11.92</td>\n",
       "      <td>5.29</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6573929/</td>\n",
       "      <td>2012-05-19T12:00:00+0900</td>\n",
       "      <td>女優 の 香里奈 が 18 日 、 都内 で 行わ れ た 映画 『 ガール 』 （ 5 月...</td>\n",
       "      <td>600</td>\n",
       "      <td>29.67</td>\n",
       "      <td>26.00</td>\n",
       "      <td>19.17</td>\n",
       "      <td>12.50</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://news.livedoor.com/article/detail/5914880/</td>\n",
       "      <td>2011-10-05T19:11:00+0900</td>\n",
       "      <td>5 日 、 東京 ・ 千代田 区 の 内幸町 ホール にて 、 映画 『 キャプテン ・ ア...</td>\n",
       "      <td>1149</td>\n",
       "      <td>33.77</td>\n",
       "      <td>25.76</td>\n",
       "      <td>15.67</td>\n",
       "      <td>10.53</td>\n",
       "      <td>10.18</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6530260/</td>\n",
       "      <td>2012-05-05T09:55:00+0900</td>\n",
       "      <td>どんな 戦士 を 作る か は ユーザー 次第 ！ 国民 的 人気 を 誇る 鳥山 明 氏 ...</td>\n",
       "      <td>793</td>\n",
       "      <td>37.58</td>\n",
       "      <td>24.34</td>\n",
       "      <td>14.25</td>\n",
       "      <td>11.98</td>\n",
       "      <td>7.82</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7363</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6681611/</td>\n",
       "      <td>2012-06-21T20:55:00+0900</td>\n",
       "      <td>galaxy siii が 6 月 28 日 、 f − 09 d anteprima が ...</td>\n",
       "      <td>293</td>\n",
       "      <td>61.09</td>\n",
       "      <td>10.24</td>\n",
       "      <td>22.53</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7364</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6856578/</td>\n",
       "      <td>2012-08-15T11:55:00+0900</td>\n",
       "      <td>shimajiro ＠ mobiler ntt ドコモ は 、 同社 の 公衆 無線 lan...</td>\n",
       "      <td>1066</td>\n",
       "      <td>49.34</td>\n",
       "      <td>21.48</td>\n",
       "      <td>16.89</td>\n",
       "      <td>7.04</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7365</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6678539/</td>\n",
       "      <td>2012-06-21T06:55:00+0900</td>\n",
       "      <td>prada phone by lg l − 02 d に ソフトウェア 更新 ！ ntt ド...</td>\n",
       "      <td>982</td>\n",
       "      <td>45.01</td>\n",
       "      <td>18.43</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.10</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7366</th>\n",
       "      <td>http://news.livedoor.com/article/detail/6869011/</td>\n",
       "      <td>2012-08-20T08:55:00+0900</td>\n",
       "      <td>ntt ドコモ は 17 日 、 公式 オンライン ショップ 「 ドコモオンラインショップ ...</td>\n",
       "      <td>504</td>\n",
       "      <td>50.79</td>\n",
       "      <td>22.02</td>\n",
       "      <td>12.50</td>\n",
       "      <td>8.13</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7367 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0     http://news.livedoor.com/article/detail/5978741/   \n",
       "1     http://news.livedoor.com/article/detail/6322901/   \n",
       "2     http://news.livedoor.com/article/detail/6176324/   \n",
       "3     http://news.livedoor.com/article/detail/6573929/   \n",
       "4     http://news.livedoor.com/article/detail/5914880/   \n",
       "...                                                ...   \n",
       "7362  http://news.livedoor.com/article/detail/6530260/   \n",
       "7363  http://news.livedoor.com/article/detail/6681611/   \n",
       "7364  http://news.livedoor.com/article/detail/6856578/   \n",
       "7365  http://news.livedoor.com/article/detail/6678539/   \n",
       "7366  http://news.livedoor.com/article/detail/6869011/   \n",
       "\n",
       "                      datetime  \\\n",
       "0     2011-10-30T10:15:00+0900   \n",
       "1     2012-02-29T11:45:00+0900   \n",
       "2     2012-01-09T14:00:00+0900   \n",
       "3     2012-05-19T12:00:00+0900   \n",
       "4     2011-10-05T19:11:00+0900   \n",
       "...                        ...   \n",
       "7362  2012-05-05T09:55:00+0900   \n",
       "7363  2012-06-21T20:55:00+0900   \n",
       "7364  2012-08-15T11:55:00+0900   \n",
       "7365  2012-06-21T06:55:00+0900   \n",
       "7366  2012-08-20T08:55:00+0900   \n",
       "\n",
       "                                                   body    WC     名詞     助詞  \\\n",
       "0     2005 年 11 月 から 翌 2006 年 7 月 まで 読売新聞 にて 連載 さ れ ...   800  42.12  23.62   \n",
       "1     「 アンテナ を 張り ながら 生活 を し て いけ ば いい 」 2 月 28 日 、 ...  1264  34.18  26.66   \n",
       "2     3 月 2 日 より 全国 ロードショー と なる 、 スティーブン ・ スピルバーグ の ...  1267  38.20  26.52   \n",
       "3     女優 の 香里奈 が 18 日 、 都内 で 行わ れ た 映画 『 ガール 』 （ 5 月...   600  29.67  26.00   \n",
       "4     5 日 、 東京 ・ 千代田 区 の 内幸町 ホール にて 、 映画 『 キャプテン ・ ア...  1149  33.77  25.76   \n",
       "...                                                 ...   ...    ...    ...   \n",
       "7362  どんな 戦士 を 作る か は ユーザー 次第 ！ 国民 的 人気 を 誇る 鳥山 明 氏 ...   793  37.58  24.34   \n",
       "7363  galaxy siii が 6 月 28 日 、 f − 09 d anteprima が ...   293  61.09  10.24   \n",
       "7364  shimajiro ＠ mobiler ntt ドコモ は 、 同社 の 公衆 無線 lan...  1066  49.34  21.48   \n",
       "7365  prada phone by lg l − 02 d に ソフトウェア 更新 ！ ntt ド...   982  45.01  18.43   \n",
       "7366  ntt ドコモ は 17 日 、 公式 オンライン ショップ 「 ドコモオンラインショップ ...   504  50.79  22.02   \n",
       "\n",
       "         記号     動詞    助動詞    副詞   連体詞   接頭詞   接続詞   形容詞   感動詞  フィラー   その他  \n",
       "0     12.00  11.88   8.12  0.88  0.50  0.38  0.25  0.25   NaN   NaN   NaN  \n",
       "1     12.66  13.13   8.86  1.98  0.55  0.47  0.08  0.87  0.40  0.16   NaN  \n",
       "2     12.47  11.92   5.29  1.03  1.34  0.95  0.47  1.82  0.40  0.16   NaN  \n",
       "3     19.17  12.50   7.50  1.67  0.50  0.67  0.67  1.33  0.33  0.16   NaN  \n",
       "4     15.67  10.53  10.18  1.48  0.70  0.26  0.78  0.87  0.33  0.16   NaN  \n",
       "...     ...    ...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7362  14.25  11.98   7.82  0.63  0.38  0.13  0.76  2.02  0.15  0.13  0.21  \n",
       "7363  22.53   3.07   2.39  0.63  0.38  0.34  0.76  0.34  0.15  0.13  0.21  \n",
       "7364  16.89   7.04   2.63  0.66  0.38  0.56  0.09  0.94  0.15  0.13  0.21  \n",
       "7365  17.01  11.10   5.91  0.51  0.20  0.51  0.51  0.81  0.15  0.13  0.21  \n",
       "7366  12.50   8.13   4.17  0.40  0.20  0.99  0.60  0.20  0.15  0.13  0.21  \n",
       "\n",
       "[7367 rows x 17 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa04c17-383a-4710-af2b-393289cc6cc9",
   "metadata": {},
   "source": [
    "## 3. Perform LDA on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50b4d822-89f3-4800-9459-6bc10fec681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read preprocessed corpus\n",
    "df = pd.read_csv(\"./preprocessed_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68ad7c06-258a-45aa-aa1c-7fad6f5f78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzer(text, mecab, stopwords=[], target_part_of_speech=['proper_noun', 'noun', 'verb', 'adjective']):\n",
    "\n",
    "    node = mecab.parseToNode(text)\n",
    "    words = []\n",
    "\n",
    "    while node:\n",
    "        features = node.feature.split(',')\n",
    "        surface = features[6]\n",
    "\n",
    "        if (surface == '*') or (len(surface) < 2) or (surface in stopwords):\n",
    "            node = node.next\n",
    "            continue\n",
    "\n",
    "        noun_flag = (features[0] == '名詞')\n",
    "        proper_noun_flag = (features[0] == '名詞') & (features[1] == '固有名詞')\n",
    "        verb_flag = (features[0] == '動詞') & (features[1] == '自立')\n",
    "        adjective_flag = (features[0] == '形容詞') & (features[1] == '自立')\n",
    "\n",
    "        if ('proper_noun' in target_part_of_speech) & proper_noun_flag:\n",
    "            words.append(surface)\n",
    "        elif ('noun' in target_part_of_speech) & noun_flag:\n",
    "            words.append(surface)\n",
    "        elif ('verb' in target_part_of_speech) & verb_flag:\n",
    "            words.append(surface)\n",
    "        elif ('adjective' in target_part_of_speech) & adjective_flag:\n",
    "            words.append(surface)\n",
    "\n",
    "        node = node.next\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc714a5-c794-483f-b062-5cc4a142fff8",
   "metadata": {},
   "source": [
    "## Adding Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "faec58b9-a353-43b0-8dec-9e6009feb273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['あそこ', 'あたり', 'あちら', 'あっち', 'あと', 'あな', 'あなた', 'あれ', 'いくつ', 'いつ', 'いま', 'いや', 'いろいろ', 'うち', 'おおまか', 'おまえ', 'おれ', 'がい', 'かく', 'かたち', 'かやの', 'から', 'がら', 'きた', 'くせ', 'ここ', 'こっち', 'こと', 'ごと', 'こちら', 'ごっちゃ', 'これ', 'これら', 'ごろ', 'さまざま', 'さらい', 'さん', 'しかた', 'しよう', 'すか', 'ずつ', 'すね', 'すべて', 'ぜんぶ', 'そう', 'そこ', 'そちら', 'そっち', 'そで', 'それ', 'それぞれ', 'それなり', 'たくさん', 'たち', 'たび', 'ため', 'だめ', 'ちゃ', 'ちゃん', 'てん', 'とおり', 'とき', 'どこ', 'どこか', 'ところ', 'どちら', 'どっか', 'どっち', 'どれ', 'なか', 'なかば', 'なに', 'など', 'なん', 'はじめ', 'はず', 'はるか', 'ひと', 'ひとつ', 'ふく', 'ぶり', 'べつ', 'へん', 'ぺん', 'ほう', 'ほか', 'まさ', 'まし', 'まとも', 'まま', 'みたい', 'みつ', 'みなさん', 'みんな', 'もと', 'もの', 'もん', 'やつ', 'よう', 'よそ', 'わけ', 'わたし', 'ハイ', '上', '中', '下', '字', '年', '月', '日', '時', '分', '秒', '週', '火', '水', '木', '金', '土', '国', '都', '道', '府', '県', '市', '区', '町', '村', '各', '第', '方', '何', '的', '度', '文', '者', '性', '体', '人', '他', '今', '部', '課', '係', '外', '類', '達', '気', '室', '口', '誰', '用', '界', '会', '首', '男', '女', '別', '話', '私', '屋', '店', '家', '場', '等', '見', '際', '観', '段', '略', '例', '系', '論', '形', '間', '地', '員', '線', '点', '書', '品', '力', '法', '感', '作', '元', '手', '数', '彼', '彼女', '子', '内', '楽', '喜', '怒', '哀', '輪', '頃', '化', '境', '俺', '奴', '高', '校', '婦', '伸', '紀', '誌', 'レ', '行', '列', '事', '士', '台', '集', '様', '所', '歴', '器', '名', '情', '連', '毎', '式', '簿', '回', '匹', '個', '席', '束', '歳', '目', '通', '面', '円', '玉', '枚', '前', '後', '左', '右', '次', '先', '春', '夏', '秋', '冬', '一', '二', '三', '四', '五', '六', '七', '八', '九', '十', '百', '千', '万', '億', '兆', '下記', '上記', '時間', '今回', '前回', '場合', '一つ', '年生', '自分', 'ヶ所', 'ヵ所', 'カ所', '箇所', 'ヶ月', 'ヵ月', 'カ月', '箇月', '名前', '本当', '確か', '時点', '全部', '関係', '近く', '方法', '我々', '違い', '多く', '扱い', '新た', 'その後', '半ば', '結局', '様々', '以前', '以後', '以降', '未満', '以上', '以下', '幾つ', '毎日', '自体', '向こう', '何人', '手段', '同じ', '感じ']\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "req = urllib.request.Request('http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt')\n",
    "\n",
    "with urllib.request.urlopen(req) as res:\n",
    "    stopwords = res.read().decode('utf-8').split('\\r\\n')\n",
    "\n",
    "while '' in stopwords:\n",
    "    stopwords.remove('')\n",
    "\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fc3ef8a1-dbe2-44e5-8a64-14e3b49341a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = df[\"body\"][0]\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Ochasen -u\" + \"user_dict.dic\")\n",
    "words = analyzer(sample_text, mecab, stopwords=stopwords, target_part_of_speech=[\"noun\", \"proper_noun\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "48d610f0-5d72-441e-9808-df0d55764bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following to see nouns and proper nouns of the first news article in dataset\n",
    "\n",
    "# words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6578118-ebc1-4319-a978-ccf26dbb748b",
   "metadata": {},
   "source": [
    "### Use gensim and the analyzer previously created in order to create a dictionary of word ids and a bag-of-words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2714bd76-d729-46fe-a07c-9361f4ef3e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished in 19.277762174606323s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "mecab = MeCab.Tagger(\"-Ochasen -u\" + \"user_dict.dic\")\n",
    "\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "texts = []\n",
    "for text in df[\"body\"]:\n",
    "    words = analyzer(text, mecab, stopwords=stopwords, target_part_of_speech=[\"noun\", \"proper_noun\"])\n",
    "    texts.append(words)\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.8)\n",
    "corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "\n",
    "# LDA\n",
    "num_topics = 20\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=num_topics,\n",
    "                                            random_state=0)\n",
    "\n",
    "print(\"finished in \" + str(time.time() - t0) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "48ea57f3-9c4b-4c46-a8d2-9330f59b8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  17528\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size: \", len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23360618-9bf9-42a7-8930-d07ba51b7cca",
   "metadata": {},
   "source": [
    "## 4. Visualize Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90f36e3f-8098-4741-a9ec-7d2b81c3fbbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1c3e259b2618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_paths' is not defined"
     ]
    }
   ],
   "source": [
    "# text = open(text_paths[0], 'r').read()\n",
    "text = \n",
    "text = text.split('\\n')\n",
    "title = text[2]\n",
    "text = ' '.join(text[3:])\n",
    "\n",
    "mecab = MeCab.Tagger('-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
    "words = analyzer(text, mecab, stopwords=stopwords, target_part_of_speech=['noun', 'proper_noun'])\n",
    "\n",
    "print(title)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a64a9c-b883-4b8b-b85c-e8c73f51694d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n----------------------------------------------------------\n\nFailed initializing MeCab. Please see the README for possible solutions:\n\n    https://github.com/SamuraiT/mecab-python3#common-issues\n\nIf you are still having trouble, please file an issue here, and include the\nERROR DETAILS below:\n\n    https://github.com/SamuraiT/mecab-python3/issues\n\nissueを英語で書く必要はありません。\n\n------------------- ERROR DETAILS ------------------------\narguments: -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n[ifs] no such file or directory: /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n----------------------------------------------------------\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/MeCab/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f371dea91c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmecab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/MeCab/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n----------------------------------------------------------\n\nFailed initializing MeCab. Please see the README for possible solutions:\n\n    https://github.com/SamuraiT/mecab-python3#common-issues\n\nIf you are still having trouble, please file an issue here, and include the\nERROR DETAILS below:\n\n    https://github.com/SamuraiT/mecab-python3/issues\n\nissueを英語で書く必要はありません。\n\n------------------- ERROR DETAILS ------------------------\narguments: -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n[ifs] no such file or directory: /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "mecab = MeCab.Tagger('-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
    "\n",
    "titles = []\n",
    "texts = []\n",
    "for text_path in text_paths:\n",
    "    text = open(text_path, 'r').read()\n",
    "    text = text.split('\\n')\n",
    "    title = text[2]\n",
    "    text = ' '.join(text[3:])\n",
    "    words = analyzer(text, mecab, stopwords=stopwords, target_part_of_speech=['noun', 'proper_noun'])\n",
    "    texts.append(words)\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.8)\n",
    "corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "\n",
    "print('vocab size: ', len(dictionary)) # vocab size:  28824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcbc0c65-ee0f-49ed-b622-7a77607ab298",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"./livedoornews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7889596-a082-44b1-8bdf-b346750cbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_citydata():\n",
    "    mt = MeCab.Tagger(\"-Ochasen -u \" + \"user_dict.dic\")\n",
    "    handler = MeCabHandler(mt)\n",
    "    wakati = []\n",
    "    pos = []\n",
    "    \n",
    "    enc = getEncode(FILENAME)\n",
    "    df = pd.read_csv(FILENAME, encoding=enc)\n",
    "\n",
    "    for txt in df[\"body\"]:\n",
    "        \n",
    "        txt = str(txt)\n",
    "        \n",
    "        filtered_text = preprocess(txt)\n",
    "        wakati.append(handler.surface(filtered_text)[1:-1])\n",
    "        pos = handler.pos(filtered_text)[1:-1]\n",
    "        \n",
    "        cnt = Counter(pos).most_common()\n",
    "        wc = len(pos)\n",
    "        dic = OrderedDict()\n",
    "#         dic['WC'] = wc\n",
    "        dic['text'] = date\n",
    "#         dic['city'] = city\n",
    "        \n",
    "        for tpl in cnt:\n",
    "            dic[tpl[0]] = '{:.2f}'.format((tpl[1] / wc)*100)\n",
    "        \n",
    "    with open(OUTPUT_PATH, 'w', encoding='utf_8_sig') as w:\n",
    "        writer = csv.writer(w, lineterminator='\\n', delimiter=' ')\n",
    "        writer.writerows(wakati)\n",
    "\n",
    "    #品詞ファイル出力\n",
    "    pd.DataFrame.from_dict(dic, orient='index').T.to_csv(POS_PATH, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c6405d5-794b-4ac1-8159-c9dfd5f7a903",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n----------------------------------------------------------\n\nFailed initializing MeCab. Please see the README for possible solutions:\n\n    https://github.com/SamuraiT/mecab-python3#common-issues\n\nIf you are still having trouble, please file an issue here, and include the\nERROR DETAILS below:\n\n    https://github.com/SamuraiT/mecab-python3/issues\n\nissueを英語で書く必要はありません。\n\n------------------- ERROR DETAILS ------------------------\narguments: -Ochasen -u user_dict.dic\n) [tokenizer_->open(param)] tokenizer.cpp(127) [d->open(dicfile[i])] dictionary.cpp(79) [dmmap_->open(file, mode)] no such file or directory: user_dict.dic \n----------------------------------------------------------\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/MeCab/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b2531fabaad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocess_citydata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-f16d4b37acf5>\u001b[0m in \u001b[0;36mpreprocess_citydata\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_citydata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeCab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-Ochasen -u \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"user_dict.dic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeCabHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwakati\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/MeCab/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rawargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n----------------------------------------------------------\n\nFailed initializing MeCab. Please see the README for possible solutions:\n\n    https://github.com/SamuraiT/mecab-python3#common-issues\n\nIf you are still having trouble, please file an issue here, and include the\nERROR DETAILS below:\n\n    https://github.com/SamuraiT/mecab-python3/issues\n\nissueを英語で書く必要はありません。\n\n------------------- ERROR DETAILS ------------------------\narguments: -Ochasen -u user_dict.dic\n) [tokenizer_->open(param)] tokenizer.cpp(127) [d->open(dicfile[i])] dictionary.cpp(79) [dmmap_->open(file, mode)] no such file or directory: user_dict.dic \n----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "preprocess_citydata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf50d4-5555-4326-a3c0-272f45a9b834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
